{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHgmxWG_7lnE"
   },
   "source": [
    "# Домашняя работа 5. Бустинг\n",
    "\n",
    "*Мягкий дедлайн: 17 декабря, 21:00*\n",
    "\n",
    "*Жесткий дедлайн: 19 декабря, 21:00*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальная оценка 5 баллов :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GOqjUI6igeLc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_boston # sorry(not sorry)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tKaz0okgeLh"
   },
   "source": [
    "### Задание 1. Градиентный бустинг своими руками  (2 балла)\n",
    "\n",
    "Вам нужно реализовать упрощенный вариант градиентного бутсинга для задачи регресси. \n",
    "\n",
    "\n",
    "**Напоминание, как это работает:**\n",
    "\n",
    "Обозначим текущую композицию на $N-1$ шаге за $a_{N - 1}(x_i)$. Базовый алгоритм $b_N(x_i)$ обучается на ответах $-\\frac{\\partial L(y_i, z)}{\\partial z}\\Bigl|_{z = a_{N - 1}(x_i)}$, где $L(y_i, z)$ — значение функции потерь на объекте при правильном ответе $y_i$ и предсказании $z$. Композиция на следующем шаге получается так:\n",
    "\n",
    "$$\n",
    "a_N(x_i) = a_{N-1}(x_i) + \\nu\\gamma_Nb_N(x_i)\n",
    "$$\n",
    "\n",
    "Здесь $\\nu \\in [0, 1]$ — темп обучения (гиперпараметр), $\\gamma_N$ — оптимальный вес, настраиваемый на каждом шаге алгоритма в ходе решения оптимизационной задачи:\n",
    "\n",
    "$$\n",
    "\\gamma_N = \\mathrm{arg}\\min_\\gamma \\frac{1}{\\ell}\\sum\\limits_{i=1}^{\\ell}L\\left(y_i, a_{N - 1}(x_i) + \\gamma b_N(x_i)\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Заметьте, что в формуле выше нет $\\nu$. Этот гиперпараметр используется для сокращения длины шага, оптимального при составлении композиции $a_N$. Идея отклонения от оптимума должна быть вам уже знакома как способ борьбы с переобучением, когда мы специально форсим модель работать чуть хуже, чем могла бы, на текущем шаге, чтобы сохранить обобщающую способность и не подогнаться под тренировочную выборку (или под шум).\n",
    "\n",
    "С потерей в 0.5 балла можете принять $\\gamma_N = 1$ для каждого $N$. На полный балл необходимо реализовать нахождение оптимального $\\gamma_N$ на каждом шаге.\n",
    "\n",
    "В качестве функции потерь $L$ возьмите MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве базовой модели можете использовать `DecisionTreeRegressor` из `sklearn`.\n",
    "Для решения оптимизационной задачки можно воспользоваться алгоритмами из любых библиотек, например, `scipy.optimize`, или найти оптимум перебором по сетке из некоторого разумного диапазона.\n",
    "\n",
    "Можно дописывать свои функции, если необходимо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "id": "ZB5Yt-LKgeLi"
   },
   "outputs": [],
   "source": [
    "class GradientBoosting:\n",
    "    def __init__(\n",
    "        self, \n",
    "        base_model_class: object = DecisionTreeRegressor,\n",
    "        base_model_params: dict = {'max_depth': None},\n",
    "        n_estimators: int = 10,\n",
    "        learning_rate: float = 0.1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        \n",
    "        Args:\n",
    "          base_model_class: Class of the base learner.\n",
    "\n",
    "          base_model_params: Hyperparameters of the base learner.\n",
    "          \n",
    "          n_estimators: Number of boosting stages.\n",
    "          \n",
    "          learning_rate: Value used to shrink contribution of each base learner to the model. \n",
    "          \n",
    "        \"\"\"\n",
    "        \n",
    "        self.base_model_class = base_model_class\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.base_model_params = base_model_params\n",
    "        \n",
    "        # list for optimal gammas at each iteration\n",
    "        self.gammas = []\n",
    "        \n",
    "        # list for base models\n",
    "        self.models = []\n",
    "        \n",
    "        # list for error tracking\n",
    "        self.errors = []\n",
    "          \n",
    "    \n",
    "    def find_optimal_gamma(self, \n",
    "                           y: np.array, \n",
    "                           old_predictions: np.array,\n",
    "                           new_predictions: np.array) -> float:\n",
    "        \"\"\"You may add arguments if it's necessary for your optimization algorithm.\n",
    "        \n",
    "        Args:\n",
    "          y: Target variable.\n",
    "\n",
    "          old_predictions: Prediction of the additive model at the previous stage.\n",
    "          \n",
    "          new_predictions: Prediction of the base learner at the current stage. \n",
    "          \n",
    "        Returns:\n",
    "          Optimal value for gamma.\n",
    "          \n",
    "        \"\"\"\n",
    "        optimal_gamma = minimize(lambda gamma: np.sum((y - old_predictions - gamma*new_predictions)**2), x0 = 1).x[0]\n",
    "        self.gammas.append(optimal_gamma)\n",
    "    \n",
    "    \n",
    "    def _fit_base_model(self, X: np.ndarray, y: np.array):\n",
    "        \"\"\"Train one base learner. \n",
    "        \n",
    "        Args:\n",
    "          X: Feature matrix\n",
    "          \n",
    "          y: Target variable.\n",
    "          \n",
    "          \n",
    "        Returns:\n",
    "          Fitted base learner.\n",
    "          \n",
    "        \"\"\"\n",
    "        base_model = DecisionTreeRegressor()\n",
    "        base_model.set_params(**self.base_model_params)\n",
    "        base_model.fit(X, y)\n",
    "        self.models.append(base_model)\n",
    "        return base_model\n",
    "    \n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.array):\n",
    "        \"\"\"Train boosting (\"sum\" of base learners). \n",
    "        \n",
    "        Args:\n",
    "          X: Feature matrix\n",
    "          \n",
    "          y: Target variable.\n",
    "          \n",
    "          \n",
    "        Returns:\n",
    "          Fitted boosting.\n",
    "          \n",
    "        \"\"\"\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            if len(self.models) == 0:\n",
    "                    self.models.append(np.zeros(X.shape[0]))\n",
    "                    self.gammas.append(1)\n",
    "            else:\n",
    "                s = 2*(y-self.predict(X))/len(X)\n",
    "                old_predictions = self.predict(X)\n",
    "                model = self._fit_base_model(X, s)\n",
    "                \n",
    "                self.find_optimal_gamma(y, old_predictions, model.predict(X))\n",
    "            if i % 2 == 0:\n",
    "                self.errors.append(mean_squared_error(y, self.predict(X)))\n",
    "        return self\n",
    "       \n",
    "        \n",
    "    def predict(self, X: np.ndarray):\n",
    "        \"\"\"Make prediction of fitted boosting. \n",
    "        \n",
    "        Args:\n",
    "          X: Feature matrix\n",
    "\n",
    "\n",
    "        Returns:\n",
    "          Prediction of fitted boosting.\n",
    "          \n",
    "        \"\"\"\n",
    "        if len(self.models) > 0:\n",
    "            y_predicted = np.zeros(X.shape[0])\n",
    "            for i, base_model in enumerate(self.models[1:]):\n",
    "                y_predicted += self.learning_rate*self.gammas[i]*base_model.predict(X)\n",
    "            return y_predicted\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте вашу реализацию на бостонском датасете. Подберите оптимальные гиперпараметры, чтобы победить RandomForestRegressor (не меняйте параметры сида)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.63198271791959"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(max_features=4, n_estimators=640, random_state=19052019)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем запустить `Gradient Boosting` с дефолтными параметрами. Зафисксируем случайный seed для воспроизводимости результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of this model is 121.41628142959033\n",
      "Wall time: 61.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gb = GradientBoosting(base_model_params={\"random_state\" : 42})\n",
    "gb.fit(X_train, y_train)\n",
    "print(f\"MSE of this model is {mean_squared_error(y_test, gb.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что разница очень велика. Попробуем подобрать по сетке гиперпараметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {\n",
    "    \"n_estimators\" : np.arange(10, 60, 2),\n",
    "    \"learning_rate\" : np.arange(0.1, 0.25, 0.025),\n",
    "    \"max_depth\" : np.arange(1, 7),\n",
    "    \"min_samples_leaf\" : np.arange(2, 5),\n",
    "    \"max_features\" : np.arange(1, 5)\n",
    "}\n",
    "keys = list(params.keys())\n",
    "combinations = np.array(np.meshgrid(*list(params.values()))).T.reshape(-1,5)\n",
    "best_MSE = None\n",
    "best_params = None\n",
    "for i in combinations:\n",
    "    base_model_params = dict(zip(keys[2:], i[2:].astype(int)))\n",
    "    base_model_params[\"random_state\"] = 42\n",
    "    gb = GradientBoosting(n_estimators=int(i[0]), learning_rate=i[1], base_model_params=base_model_params)\n",
    "    gb.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(y_test, gb.predict(X_test))\n",
    "    if best_MSE is None:\n",
    "        best_MSE = mse\n",
    "        best_params = i\n",
    "    if mse < best_MSE:\n",
    "        best_MSE = mse\n",
    "        best_params = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры и скор лучшей модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model:\n",
      "\tn_estimators : 58.0\n",
      "\tlearning_rate : 0.15\n",
      "\tmax_depth : 6.0\n",
      "\tmin_samples_leaf : 4.0\n",
      "\tmax_features : 4.0\n",
      "MSE of the best model is 8.815345865232844\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameters of the best model:\")\n",
    "for i, key in enumerate(keys):\n",
    "    print(f\"\\t{key} : {best_params[i]}\")\n",
    "print(f\"MSE of the best model is {best_MSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге, я подобрал гиперпараметры, которые победили RandomForest, хотя и кажется, что здесь randomforest лучше справляется. При переборе гиперпараметров можно было еще сделать early stopping, но я слишком поздно это понял и мне лень еще раз запускать это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.815345865232844"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model once again\n",
    "gb = GradientBoosting(n_estimators=58, learning_rate=0.15, base_model_params={'max_depth':6, \"min_samples_leaf\":4, \"max_features\":4, \"random_state\":42})\n",
    "gb.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, gb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Best model train')"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(np.arange(len(gb.errors))*2, gb.errors)\n",
    "plt.xlabel(\"n_iteration\")\n",
    "plt.ylabel('MSE on train')\n",
    "plt.title(\"Best model train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2. Сравнение подходов (1.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте данные о выдаче кредитов. Это данные с kaggle, целевая переменная `y` показывает, вернуло ли кредит физическое лицо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget  -O 'bank_data.csv' -q 'https://www.dropbox.com/s/uy27mctxo0gbuof/bank_data.csv?dl=0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>57</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.354</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6251</th>\n",
       "      <td>30</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>apr</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.405</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8125</th>\n",
       "      <td>49</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>divorced</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.957</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8714</th>\n",
       "      <td>29</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.965</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6647</th>\n",
       "      <td>64</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.876</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>0.697</td>\n",
       "      <td>5008.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age          job   marital          education  default housing loan  \\\n",
       "6043   57       admin.    single  university.degree       no      no  yes   \n",
       "6251   30     services    single        high.school  unknown     yes   no   \n",
       "8125   49  blue-collar  divorced            unknown  unknown      no   no   \n",
       "8714   29       admin.    single  university.degree       no      no  yes   \n",
       "6647   64    housemaid   married            unknown       no     yes   no   \n",
       "\n",
       "        contact month day_of_week  ...  campaign  pdays  previous  \\\n",
       "6043   cellular   may         mon  ...         3    999         0   \n",
       "6251  telephone   apr         fri  ...         1    999         0   \n",
       "8125   cellular   jul         wed  ...         2    999         0   \n",
       "8714   cellular   aug         mon  ...         2    999         0   \n",
       "6647  telephone   may         wed  ...         3    999         0   \n",
       "\n",
       "         poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "6043  nonexistent         -1.8          92.893          -46.2      1.354   \n",
       "6251  nonexistent         -1.8          93.075          -47.1      1.405   \n",
       "8125  nonexistent          1.4          93.918          -42.7      4.957   \n",
       "8714  nonexistent          1.4          93.444          -36.1      4.965   \n",
       "6647  nonexistent         -1.8          93.876          -40.0      0.697   \n",
       "\n",
       "      nr.employed  y  \n",
       "6043       5099.1  1  \n",
       "6251       5099.1 -1  \n",
       "8125       5228.1 -1  \n",
       "8714       5228.1 -1  \n",
       "6647       5008.7  1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bank_data.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решите задачу предсказания возвращения кредита методами, перечисленными ниже:\n",
    "\n",
    "- Случайный лес\n",
    "- Бэггинг на деревьях (поставьте для базовых деревьев min_samples_leaf=1)\n",
    "- Бэггинг, у которого базовой моделью является бустинг с большим числом деревьев (> 100)\n",
    "- Бэггинг на логистических регрессиях\n",
    "\n",
    "Используйте логистическую регрессию, случайный лес, `GradientBoostingClassifier` и `BaggingClassifier` из `sklearn`.\n",
    "\n",
    "1) Какая из моделей имеет лучшее качество? С чем это связано?\n",
    "\n",
    "2) Какая из моделей сильнее всего переобучается?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Современные бустинги (1.5 балла)\n",
    "\n",
    "Сравните на этих данных любую из трёх популярных имплементаций градиентного бустинга (xgboost, lightgbm, catboost). Подберите основные гиперпараметры (число деревьев, длина шага, глубина дерева/число листьев). Получилось ли круче, чем с моделями выше?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бонус (0.1 балла)\n",
    "\n",
    "Прикрепите сюда что-нибудь для новогоднего настроения 👒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сюда"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw8-boosting-clustering.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
